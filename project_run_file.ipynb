{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Measures of freedom - Hannah Costa\n",
    "\n",
    "## Introduction\n",
    "\n",
    "'''\n",
    "The Human Freedom Index is an annual survey that looks to categorise, quantify and rank the different \n",
    "economic, social and civil freedoms that a country provides its people. These quantities are tracked \n",
    "and published every year and the processed data made available to teh public.\n",
    "\n",
    "The motiviations behind this analysis revolve around probing the correlations between the Women's social\n",
    "and security factor in the regions of the world where women's rights are most at risk. This strictly \n",
    "doesn't equate to 'business objective', but if we position ourselves where we seek value in the Human \n",
    "Freedom data then we must undersand the data and it's purpose in the same manner that would align to a \n",
    "business objective. \n",
    "\n",
    "Quantifying a variable like Freedom is an interesting task in itself to put a unit or a comparable scale on \n",
    "an intangible concept, but something, even as an observation has worth when it is analysed with our \n",
    "motivations in mind. Personally, I can see no point of a Human Freedom Index, other than a numerical exercise\n",
    "if it is not used to point out where certain freedoms are lacking or declining. To understand this and provide\n",
    "insight into the complex correlations around Women's Social Security is the starting point of this analysis.\n",
    "\n",
    "The following questions are addressed in the project:\n",
    "\n",
    "    1. Do the different regions of the world have a distinct looking relationship between Women's rights and \n",
    "    their overall freedom status?\n",
    "\n",
    "The assumption here is that the Women's Social and Security factor's relationship with the overall freedom \n",
    "score is culturally driven. Borders between countries have not always been static and in some regions are \n",
    "still volitile. Countries that border each other can have a shared cultural history and it is expected that \n",
    "the relationship plotted will form clusters. Some tighter than others, and it will be interesting to further\n",
    "investigate the outliers in the regions. \n",
    "\n",
    "    2. For the Region where the Women's SS scores are typically high and the Region where they are typically\n",
    "    low, is there a high or low variance between countries within the same region and are there cultural \n",
    "    similarities in the outliers where Women's SS in particularily low.\n",
    "\n",
    "An outlier in a country that has equal women's rights will have a very different stroy to a country in a region \n",
    "still struggling for women's rights. But for the region with lowest women's rights are there other factors that \n",
    "add to thier cultural identify that might give some insights into teh descrency in women's freedom.\n",
    "\n",
    "    3. Are there factors that are not in the Human Freedom Index that could better correlate to women's freedom?\n",
    "\n",
    "This analysis was don't outside python as it uses a list of Muslim countries (>95% Muslim representation) that \n",
    "impliment Sharia Law and a sample of Muslim countries that do not. This is cited and given in the Blog post \n",
    "portion of the assignment and as the information needed was directly visable in the Human Freedom Index report\n",
    "it was a trivial task to note the value into a table. The resulting graph also given in the medium Blog post.\n",
    "\n",
    "https://hannahirons88.medium.com/the-measures-of-freedom-c564657ce860\n",
    "\n",
    "The complimentary analysis outside of python demonstrated that there are area's missing or under represented in \n",
    "the Human Freedom Index as a handful of countries I wanted to look at (that had Sharia law in some variation) \n",
    "were not included in the data/report. On the global stage, freedom, or lack of it, is a controversial topic \n",
    "especially with regards to a sub set of people (women in this scenario). It is likely that the excluded countries \n",
    "would countain a freedom bias in the areas potentially most vunerable. This led me to form the final question of \n",
    "this analysis, which returns to python and this notebook.\n",
    "\n",
    "    4. Where social freedom data is not available, could it be possible to find correlations in other factors\n",
    "    strong enough to offer a prediction into whether Women's safety and security are at risk?\n",
    "    \n",
    "This is where it not just important to understand your data but where it can be trusted too. The point of this \n",
    "question is to build a model to predict a social freedom using only economic factors. The top correlatated factors\n",
    "were pulled out to understand what the strongest factors in the model would be and if they made any sense in them \n",
    "being there. \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "'''\n",
    "The following cell contains the functions built for the data prep, analysis and visualisation of this project. \n",
    "The cell is to be run first so that all functions are available to be called in later sections of the code. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def convert_float(dataframe):\n",
    "  '''\n",
    "  INPUT\n",
    "    dataframe - any dataframe acceptable.\n",
    "    col - local variable, used to go through all columns in the dataframe.\n",
    "  OUTPUT\n",
    "    dataframe - global varable. The input dataframe is replaced in the function. If the following \n",
    "    logic is applicable on a column level.  \n",
    "\n",
    "  The function will cycle through each column in the dataframe and replace any dashes or spaces\n",
    "  with the NaN value definition from the numpy library. If the column is numeric in nature but\n",
    "  formatted as an object it will change it's datatype to a float. If the column is naturally a \n",
    "  string then the function will print \"Could not convert\", followed by the column name and move\n",
    "  on to the next column.\n",
    "\n",
    "  While debugging this function and viewing the dataset, at first look I believed all blanks in \n",
    "  the data were denoted by a '-', however one factor - that was a scored factor - was failing \n",
    "  (ef_regulation_labor_dismissal), and the currently commented out section identified the row in \n",
    "  that column that failed and that it was an empty space. \n",
    "\n",
    "  Therefore, if a column that you expect to able to turn into a float fails, then you can \n",
    "  uncomment the green section and rerun the function to get the row number that is failing, and \n",
    "  subsequently find out why it failed. I've kept it commented out because if the whole column\n",
    "  fails for another reason then it will print every row of that column, so it's best used when\n",
    "  a problem column has already been identified.   \n",
    "  '''\n",
    "\n",
    "\n",
    "  for col in dataframe:\n",
    "    try:\n",
    "      dataframe[col] = dataframe[col].replace(['-', ' '], np.NaN)\n",
    "      dataframe[col] = dataframe[col].astype(float)\n",
    "    except:\n",
    "      # uncomment the following three lines to debug a failing column that should be able convert.\n",
    "      # for row in dataframe[col]:\n",
    "      #   if not isinstance(row, float):\n",
    "      #     print(row)\n",
    "      print('Could not convert ' + col)\n",
    "\n",
    "\n",
    "def most_missing_col(dataframe, threshold):\n",
    "  '''\n",
    "  INPUT\n",
    "    dataframe - the processed dataframe, with NaNs.\n",
    "    threshold - the threshold for percenatge of missing values.\n",
    "  OUTPUT\n",
    "    missing_col_list - list of variables that have more missing values than the threshold identified.\n",
    "\n",
    "  The function will create a list of variables from the dataframe that have a greater percentage of\n",
    "  missing values than provided by the threshold input. \n",
    "  '''\n",
    "\n",
    "  missing_col_list = list(dataframe.columns[dataframe.isnull().mean() > threshold])\n",
    "\n",
    "  return missing_col_list\n",
    "\n",
    "\n",
    "def country_per_region(selected_region, response, dataframe):\n",
    "  '''\n",
    "  INPUT\n",
    "    selected_region - any region defined by the dataset\n",
    "    response - which variable you want to take the mean of over the region\n",
    "    dataframe - the dataset that contains Region\n",
    "  OUTPUT\n",
    "    out_data - the aggregated mean of the reponse variable over the selected region.\n",
    "\n",
    "  This function works well to loop over multiple regions, or variables to get the mean\n",
    "  of that variable for each region. It can be called inside a loop. But works fine\n",
    "  on its own.\n",
    "\n",
    "'''\n",
    "\n",
    "  out_data = dataframe[dataframe[\"region\"] == selected_region].groupby([\"countries\"]).mean()[response]\n",
    "\n",
    "  return out_data\n",
    "\n",
    "\n",
    "def plot_save_Region_correlation(var_1, var_2, region):\n",
    "  '''\n",
    "  INPUT\n",
    "    var_1 - an input variable for plotting\n",
    "    var_2 - an input varaible for plotting \n",
    "    region - for a selected region\n",
    "  OUTPUT\n",
    "    saved plot. no global returned variable.\n",
    "\n",
    "  This function produces and saves a graph to compare two variables for a filtered region.\n",
    "\n",
    "  '''\n",
    "  save_name = \"women's_freedom_correlated_with_freedom_score_for_\" + region\n",
    "\n",
    "  plt.figure(figsize = (10,8))\n",
    "  plt.subplots_adjust(bottom = 0.2)\n",
    "\n",
    "  plt.plot(var_1, linestyle = 'solid', color = 'r')\n",
    "  plt.plot(var_2, linestyle = 'solid', color = '#4b0082')\n",
    "  plt.ylabel(\"variable score\")\n",
    "  plt.xlabel(\"country\")\n",
    "  plt.xticks(rotation = 90)\n",
    "  plt.legend((\"Human Freedom Score\", \"Personal woman's score\"), loc = 'lower right')\n",
    "  plt.grid(True)\n",
    "\n",
    "  plt.title(\"The average personal women's freedom score aggregated for the top correlated factors. \\n Region = \" + region)\n",
    "\n",
    "  plt.savefig('./results/' + save_name + '.png')\n",
    "  plt.close()\n",
    "\n",
    "\n",
    "def correlations_top_bottom(dataframe, region_select, var, n):\n",
    "  '''\n",
    "  INPUT\n",
    "    dataframe - the proccessed dataframe, must contain region.\n",
    "    region_select - the selected region\n",
    "    var - the response variable to check correlations against\n",
    "    n - number of variables to print\n",
    "  OUTPUT\n",
    "    Print top - print the highest correlated factors\n",
    "    Print bottom - print the highest anti-correlated factors\n",
    "\n",
    "  This function prints out the highest correlated and anti-correlated factors compared with a given variable.\n",
    "  The number of highest factors printed is given by n.\n",
    "\n",
    "  '''\n",
    "\n",
    "  correlations = dataframe[dataframe[\"region\"] == region_select].corr()\n",
    "  sorted_corr = correlations[var].sort_values()\n",
    "\n",
    "  Top = sorted_corr[-n:]\n",
    "  print(Top)\n",
    "  Bottom = sorted_corr[:n]\n",
    "  print(Bottom)\n",
    "\n",
    "\n",
    "def variable_per_region(selected_region, var, response, dataframe):\n",
    "  '''\n",
    "  INPUT\n",
    "    selected_region - region of interest\n",
    "    var - correlated variable of interest\n",
    "    response - the orginal variable it was checked for correlations against. \n",
    "  OUTPUT\n",
    "    out_data - the relationship between the correlated pair for a selected region.\n",
    "\n",
    "  This function gives the mean value of the correlated factor to the response factor for a\n",
    "  given region so that they can be plotted before potential modelling.\n",
    "\n",
    "'''\n",
    "\n",
    "  out_data = dataframe[dataframe[\"region\"] == selected_region].groupby([var]).mean()[response]\n",
    "\n",
    "  return out_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Run sections of the code. The project and analysis is structured in the cells that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year ISO_code  countries                         region hf_score hf_rank  \\\n",
      "0  2017      ALB    Albania                 Eastern Europe     7.84      38   \n",
      "1  2017      DZA    Algeria     Middle East & North Africa     4.99     155   \n",
      "2  2017      AGO     Angola             Sub-Saharan Africa      5.4     151   \n",
      "3  2017      ARG  Argentina  Latin America & the Caribbean     6.86      77   \n",
      "4  2017      ARM    Armenia        Caucasus & Central Asia     7.42      54   \n",
      "\n",
      "  hf_quartile pf_rol_procedural pf_rol_civil pf_rol_criminal  ...  \\\n",
      "0           1               6.7          4.5             4.7  ...   \n",
      "1           4                 -            -               -  ...   \n",
      "2           4                 -            -               -  ...   \n",
      "3           2               7.1          5.8             4.3  ...   \n",
      "4           2                 -            -               -  ...   \n",
      "\n",
      "  ef_regulation_business_adm ef_regulation_business_bureaucracy  \\\n",
      "0                        6.3                                6.7   \n",
      "1                        3.7                                1.8   \n",
      "2                        2.4                                1.3   \n",
      "3                        2.5                                7.1   \n",
      "4                        4.6                                6.2   \n",
      "\n",
      "  ef_regulation_business_start ef_regulation_business_bribes  \\\n",
      "0                          9.7                           4.1   \n",
      "1                          9.3                           3.8   \n",
      "2                          8.7                           1.9   \n",
      "3                          9.6                           3.3   \n",
      "4                          9.9                           4.6   \n",
      "\n",
      "  ef_regulation_business_licensing ef_regulation_business_compliance  \\\n",
      "0                                6                               7.2   \n",
      "1                              8.7                                 7   \n",
      "2                              8.1                               6.8   \n",
      "3                              5.4                               6.5   \n",
      "4                              9.3                               7.1   \n",
      "\n",
      "  ef_regulation_business ef_regulation ef_score ef_rank  \n",
      "0                    6.7           7.8     7.67      30  \n",
      "1                    5.7           5.4     4.77     159  \n",
      "2                    4.9           5.7     4.83     158  \n",
      "3                    5.7           5.6     5.67     147  \n",
      "4                    6.9           7.5      7.7      27  \n",
      "\n",
      "[5 rows x 120 columns]\n"
     ]
    }
   ],
   "source": [
    "# Prepare Data\n",
    "## 1. Import Libraries\n",
    "## 2. Locate and read in data csv\n",
    "## 3. Check import by viewing data head\n",
    "\n",
    "'''\n",
    "RUN file for Udacity Data science nanodegree: Project One - Write a Data Science Blog Post\n",
    "Author: Hannah Costa\n",
    "\n",
    "The data chosen for this assigmnet was the Human Freedom Index data avaialble on Kaggle.\n",
    "LINK: https://www.kaggle.com/gsutters/the-human-freedom-index\n",
    "\n",
    "The Human Index data combines measures of economic and personal freedom to assign a total \n",
    "Human Freedom score to a country and rank it based on this score. The survey has been \n",
    "conducted since 2008 for the earliest definition, and the most recent data availiable is \n",
    "from 2019, which is used in this assignment. \n",
    "\n",
    "The data available isn't the raw data from the Freedom project, and is made up of the economic \n",
    "and personal freedom factors that are all on a scored scale between 0-10. The Human Freedom \n",
    "report offers some insight in the meanings behind these factors but their definitions, \n",
    "or what the score directly translates to numerically is unknown.\n",
    "\n",
    "For example the pf_ss_women_fgm factor relates to Female Genital Mutilations in a country, but \n",
    "the score doesn't tell me if it's based on number of cases reported per population percentage.\n",
    "'pf' in a factor means that it's used to create a Personal Freedom Factor and 'ss' means it's \n",
    "in the 'Security and Safety' category. \n",
    "\n",
    "The freedom indicators covered by the report are:\n",
    "\n",
    "Rule of Law\n",
    "Security and Safety\n",
    "Movement\n",
    "Religion\n",
    "Association, Assembly, and Civil Society\n",
    "Expression and Information\n",
    "Identity and Relationships\n",
    "Size of Government\n",
    "Legal System and Property Rights\n",
    "Access to Sound Money\n",
    "Freedom to Trade Internationally\n",
    "Regulation of Credit, Labor, and Business\n",
    "\n",
    "This Run file will call functions and scripts with the purpose of reading in the data and \n",
    "processing it so it can be used to explore correlations and insights in the data while\n",
    "focusing on the implications of women's freedom. The author is using python 3.8.5 in Jupyter notebook.\n",
    "\n",
    "'''\n",
    "# Call the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Read dataset into a dataframe\n",
    "df = pd.read_csv('./data/datasets_93172_883723_hfi_cc_2019.csv')\n",
    "# Check the first handful of rows to ensure the data was retrieved. note: 120 columns expected\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Understanding and preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the processed nature of the data set I want to drop some of the factors that\n",
    "# are generated by the more base factors.\n",
    "df = df.drop([\"ISO_code\", \"ef_score\",\"pf_score\", \"pf_rank\", \"ef_rank\", \"hf_rank\", \"hf_quartile\"], axis = 1)\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data - processing formatting to make the dataset usable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert countries\n",
      "Could not convert region\n"
     ]
    }
   ],
   "source": [
    "# The whole dataset comes in as \"objects\" despite the majority of the data being a numerical score. \n",
    "# The next step would be to convert the columns that can be converted to floats in order to be able\n",
    "# to perform numerical analysis on the dataset. \n",
    "\n",
    "convert_float(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The print out should read \"Could not convert countries\" and \"Could not convert region\", which is expected\n",
    "# as they are strings and can remain as an object in formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with missing data and dropping columns. The dropped columns are listed in the outpiut so we are aware \n",
    "# of which factors are being removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pf_rol_procedural', 'pf_rol_civil', 'pf_rol_criminal', 'pf_ss_women_inheritance_widows', 'pf_ss_women_inheritance_daughters', 'pf_religion_estop_establish', 'pf_religion_estop_operate', 'pf_association_political_establish', 'pf_association_political_operate', 'pf_association_prof_establish', 'pf_association_prof_operate', 'pf_association_sport_establish', 'pf_association_sport_operate', 'pf_identity_legal']\n"
     ]
    }
   ],
   "source": [
    "# create a list of columns that have more than 25% of their values missing.\n",
    "col_list = most_missing_col(df, 0.25)\n",
    "\n",
    "# Check column list to be aware of what's being dropped\n",
    "print(col_list)\n",
    "\n",
    "# Drop the columns that have the most missing values\n",
    "df = df.drop(col_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business understanding and Evaluation of results\n",
    "'''\n",
    "The following section addresses questions one and two. Region is seperated out as a list and looped \n",
    "over to extract the appropriate data for Women's Social and Security score and the overall Human\n",
    "Freedom score. These are then plotted together (for each region) and the figures are save in the\n",
    "results location: /results/, just a directory down from the notebook location.\n",
    "\n",
    "The plots paint an interesting picture between the regions, highlighting the difference between first \n",
    "world, developing and third world regions. For economically richer regions, both Women's social and \n",
    "security factor and the overall Human Freedom score are high, with the women's factor being mostly \n",
    "above 9 and the overall freedom score a couple of points lower. The variance between country is low \n",
    "and the gap between womens and overall freedom score is pretty constant. For economically poorer regions\n",
    "both scores are low but in comparison to Western Europe the women's score has taken a larger hit. It's\n",
    "also much more volatile, with outliers having a relatively high women's score and a number of outliers \n",
    "having the lowest overall women's score in the world.\n",
    "\n",
    "Further analysis into lower women's freedom score will use the region described by Sub-Saharan Africa\n",
    "as it's a large region with some unique trends.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region_list = list(set(df[\"region\"]))\n",
    "\n",
    "# Check that region_list has populated correctly\n",
    "# print(Region_list)\n",
    "\n",
    "# Loop over region_list for average scores for hf_score and pf_ss_women score. Plot togther for \n",
    "# each country per region. Save the figures so they do not overwrite each other. \n",
    "\n",
    "for region in Region_list:\n",
    "  region_pf_women = country_per_region(region, \"pf_ss_women\", df)\n",
    "  region_hf_score = country_per_region(region, \"hf_score\", df)\n",
    "  plot_save_Region_correlation(region_hf_score, region_pf_women, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Modelling\n",
    "'''\n",
    "Having probed in some interesting areas of the data we've started understand what kind of model\n",
    "we want to build. The following section addresses question four in our motivations. \n",
    "\n",
    "The purpose of the model is to see whether you could predict the Women's social and security \n",
    "score (or any personal freedom factor) from factors that it doesn't consist of, and even if you can\n",
    "use only the econmic freedom factors to create a prediction.\n",
    "\n",
    "This would give some insight into how strongly linked a countries economic freedom (linked to \n",
    "econmic wealth) is to it's women's rights, i.e is the a gendered skew in non-gendered factors. \n",
    "Secondary to this is that where data is not available, and it seems that the more controversial\n",
    "personal freedoms had the nighest percentage of missing values, can we predict is women's rights\n",
    "are suffering in areas where the data is hard to ascertian.\n",
    "\n",
    "However in digging into the data on a country level (see blog post), the countries that are excluded\n",
    "from the data have a high potential for a freedom bias that if available could impact any model. \n",
    "\n",
    "We can start by printing out the highest positive and negative correlations for pf_ss_women for\n",
    "Sub-Saharan Africa.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ef_legal                         0.271014\n",
      "ef_legal_protection              0.303193\n",
      "ef_regulation_business_bribes    0.305410\n",
      "ef_legal_military                0.309798\n",
      "ef_legal_judicial                0.360162\n",
      "hf_score                         0.380304\n",
      "pf_ss                            0.637599\n",
      "pf_ss_women_inheritance          0.759284\n",
      "pf_ss_women_fgm                  0.802604\n",
      "pf_ss_women                      1.000000\n",
      "Name: pf_ss_women, dtype: float64\n",
      "ef_government_transfers       -0.349969\n",
      "ef_trade_tariffs_sd           -0.246652\n",
      "ef_government_consumption     -0.231973\n",
      "ef_regulation_labor_firing    -0.200293\n",
      "ef_legal_integrity            -0.194131\n",
      "ef_regulation_labor_bargain   -0.151508\n",
      "pf_association_assembly       -0.114447\n",
      "pf_association_political      -0.099305\n",
      "ef_legal_enforcement          -0.090885\n",
      "ef_government_soa             -0.074465\n",
      "Name: pf_ss_women, dtype: float64\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(correlations_top_bottom(df, \"Sub-Saharan Africa\", \"pf_ss_women\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data modelling\n",
    "'''\n",
    "pf_ss_women_'inheritance/fgm'are used to create pf_ss_women so of course the correlations are high \n",
    "and we can't use them in teh model because we're acting in teh assumption that these values would be\n",
    "missing. \n",
    "\n",
    "Next we take a look of the correlation for the highest correlated economic freedom factors for Sub-\n",
    "Saharan Africa, and use a plot to visualise it.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closer look at the correlation for Sub Saharan Africa\n",
    "var_list = [\"ef_legal_judicial\", \"ef_legal_military\", \"ef_regulation_business_bribes\", \"ef_government_transfers\", \"ef_trade_tariffs_sd\", \"ef_government_consumption\"]\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.xlabel(\"variable score\")\n",
    "plt.ylabel(\"mean pf_ss_women score\")\n",
    "plt.title(\"The average personal women's freedom score aggregated for the top correlated factors. \\n Sub-Saharan Africa\")\n",
    "plt.grid(True)\n",
    "\n",
    "d = {}\n",
    "for var in var_list:\n",
    "  d[var] = variable_per_region(\"Sub-Saharan Africa\", var, \"pf_ss_women\", df)\n",
    "  plt.plot(d[var], 'o')\n",
    "\n",
    "plt.legend((var_list), loc ='lower right')\n",
    "plt.savefig('./results/scatter_correlations_SSA.png')\n",
    "\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further data cleaning and data modelling\n",
    "# The last step is to build a simple linear regression model and split in between training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ef_government_transfers worked as expected\n",
      "The Model performed with a Score of 0.5401751775708902\n"
     ]
    }
   ],
   "source": [
    "#  Can you model womens's freedomn using only economic factors per region.\n",
    "df_modelling = df.dropna(subset = [\"pf_ss_women\"], axis = 0)\n",
    "\n",
    "X = df_modelling.filter(regex = '^ef', axis = 1)\n",
    "y = df_modelling[\"pf_ss_women\"]\n",
    "\n",
    "fill_mean = lambda col: col.fillna(col.mean())\n",
    "\n",
    "# I've kept the following function inside the run_file instead of the function_file to toggle the different print functions on and off when debugging.\n",
    "for col in X:\n",
    "  if X[col].isnull().sum() == 0:\n",
    "    # print(col + \" no NaN's\")\n",
    "    continue\n",
    "  else:\n",
    "    try:\n",
    "      X = X.apply(fill_mean, axis = 0)\n",
    "      print(col + \" worked as expected\")\n",
    "    except:\n",
    "      print(col + \" did not replace NaN with mean\")\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 15)\n",
    "lm_model = LinearRegression(normalize = True)\n",
    "lm_model.fit(X_train, y_train)\n",
    "\n",
    "Score = str(lm_model.score(X_test, y_test, sample_weight = None))\n",
    "\n",
    "print(\"The Model performed with a Score of \" + Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "After visualising the top correlations it's not very suprising that the model performs poorly \n",
    "even when it's allowed to use all the economic freedom factors. It scored 0.54 [2dp] on the 20%\n",
    "left over test dataset.\n",
    "\n",
    "There is some correlation and trend between the different categories of freedom quantified by\n",
    "the HFI, but they are seperate because they represent very different types of freedom that\n",
    "someone can experience and the total Freedom score needs data on both personal and economic freedoms.\n",
    "\n",
    "But when we're looking for vunerability in the freedoms of a subset of people within a country it \n",
    "does still seem linked to it's outward preception of economic wealth and strength. There are exceptions\n",
    "to this where a country still values it's women's rights and it scores significantly higher than it's \n",
    "overall freedom score (Cape Verde, Seychelles) and others with a relatively string freedom score that\n",
    "still manages to hide a low women's score with it (Brunei). \n",
    "\n",
    "Please refer to the Medium blog post that supports this proect for a full dicsussion of the results\n",
    "https://hannahirons88.medium.com/the-measures-of-freedom-c564657ce860\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
